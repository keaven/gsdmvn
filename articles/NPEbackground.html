<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>Non-Proportional Effect Size in Group Sequential Design • gsdmvn</title>
<!-- jquery --><script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js" integrity="sha256-CSXorXvZcTkaix6Yvo6HppcZGetbYMGWSFlBw8HfCJo=" crossorigin="anonymous"></script><!-- Bootstrap --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.4.1/css/bootstrap.min.css" integrity="sha256-bZLfwXAP04zRMK2BjiO8iu9pf4FbLqX6zitd+tIvLhE=" crossorigin="anonymous">
<script src="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.4.1/js/bootstrap.min.js" integrity="sha256-nuL8/2cJ5NDSSwnKD8VqreErSWHtnEP9E7AySL+1ev4=" crossorigin="anonymous"></script><!-- bootstrap-toc --><link rel="stylesheet" href="../bootstrap-toc.css">
<script src="../bootstrap-toc.js"></script><!-- Font Awesome icons --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/all.min.css" integrity="sha256-mmgLkCYLUQbXn0B1SRqzHar6dCnv9oZFPEC1g1cwlkk=" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/v4-shims.min.css" integrity="sha256-wZjR52fzng1pJHwx4aV2AO3yyTOXrcDW7jBpJtTwVxw=" crossorigin="anonymous">
<!-- clipboard.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><!-- headroom.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/headroom.min.js" integrity="sha256-AsUX4SJE1+yuDu5+mAVzJbuYNPHj/WroHuZ8Ir/CkE0=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/jQuery.headroom.min.js" integrity="sha256-ZX/yNShbjqsohH1k95liqY9Gd8uOiE1S4vZc+9KQ1K4=" crossorigin="anonymous"></script><!-- pkgdown --><link href="../pkgdown.css" rel="stylesheet">
<script src="../pkgdown.js"></script><meta property="og:title" content="Non-Proportional Effect Size in Group Sequential Design">
<meta property="og:description" content="gsdmvn">
<!-- mathjax --><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js" integrity="sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA=" crossorigin="anonymous"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]-->
</head>
<body data-spy="scroll" data-target="#toc">
    <div class="container template-article">
      <header><div class="navbar navbar-default navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <span class="navbar-brand">
        <a class="navbar-link" href="../index.html">gsdmvn</a>
        <span class="version label label-default" data-toggle="tooltip" data-placement="bottom" title="Released version">0.1.0</span>
      </span>
    </div>

    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
<li>
  <a href="../index.html">
    <span class="fas fa fas fa-home fa-lg"></span>
     
  </a>
</li>
<li>
  <a href="../reference/index.html">Reference</a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Articles
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
<li>
      <a href="../articles/DesignWithSpending.html">Trial design with spending under NPH</a>
    </li>
    <li>
      <a href="../articles/NPEbackground.html">Non-Proportional Effect Size in Group Sequential Design</a>
    </li>
    <li>
      <a href="../articles/NPEbounds.html">Computing Bounds Under Non-Constant Treatment Effect</a>
    </li>
    <li>
      <a href="../articles/QuickStart.html">Quick Start for NPH Sample Size and Power</a>
    </li>
  </ul>
</li>
<li>
  <a href="../news/index.html">Changelog</a>
</li>
      </ul>
<ul class="nav navbar-nav navbar-right"></ul>
</div>
<!--/.nav-collapse -->
  </div>
<!--/.container -->
</div>
<!--/.navbar -->

      

      </header><script src="NPEbackground_files/accessible-code-block-0.0.1/empty-anchor.js"></script><div class="row">
  <div class="col-md-9 contents">
    <div class="page-header toc-ignore">
      <h1 data-toc-skip>Non-Proportional Effect Size in Group Sequential Design</h1>
            
      
      
      <div class="hidden name"><code>NPEbackground.Rmd</code></div>

    </div>

    
    
<div id="overview" class="section level1">
<h1 class="hasAnchor">
<a href="#overview" class="anchor"></a>Overview</h1>
<p>The acronym NPES is short for non-proportional effect size. While it is motivated primarily by a use for when designing a time-to-event trial under non-proportional hazards (NPH), we have simplified and generalized the concept here. The model is likely to be useful for rank-based survival tests beyond the logrank test that will be considered initially by <span class="citation">Tsiatis (1982)</span>. It could also be useful in other situations where treatment effect may vary over time in a trial for some reason. We generalize the framework of Chapter 2 of <span class="citation">Proschan, Lan, and Wittes (2006)</span> to incorporate the possibility of the treatment effect changing during the course of a trial in some systematic way. This vignettes addresses distribution theory and initial technical issues around computing</p>
<ul>
<li>boundary crossing probabilities</li>
<li>bounds satisfying targeted boundary crossing probabilities</li>
</ul>
<p>This is then applied to generalize computational algorithms provided in Chapter 19 of <span class="citation">Jennison and Turnbull (2000)</span> that are used to compute boundary crossing probabilities as well as boundaries for group sequential designs. Additional specifics around boundary computation, power and sample size are provided in a separate vignette.</p>
</div>
<div id="the-probability-model" class="section level1">
<h1 class="hasAnchor">
<a href="#the-probability-model" class="anchor"></a>The probability model</h1>
<div id="the-continuous-model-and-e-process" class="section level2">
<h2 class="hasAnchor">
<a href="#the-continuous-model-and-e-process" class="anchor"></a>The continuous model and E-process</h2>
<p>We consider a simple example here to motivate distribution theory that is quite general and applies across many situations. For instance <span class="citation">Proschan, Lan, and Wittes (2006)</span> immediately suggest paired observations, time-to-event and binary outcomes as endpoints where the theory is applicable.</p>
<p>We assume for a given integer <span class="math inline">\(N&gt;0\)</span> that <span class="math inline">\(X_{i}\)</span> are independent, <span class="math inline">\(i=1,2,\ldots\)</span>. For some integer <span class="math inline">\(K\le N\)</span> we assume we will perform analysis <span class="math inline">\(K\)</span> times after <span class="math inline">\(0&lt;n_1&lt;n_2,\ldots ,n_K = N\)</span> observations are available for analysis. Note that we have not confined <span class="math inline">\(n\le N\)</span>, but <span class="math inline">\(N\)</span> can be considered the final planned sample size. <span class="citation">Proschan, Lan, and Wittes (2006)</span> refer to the estimation or E-process which we extend here to</p>
<p><span class="math display">\[\hat{\theta}_k = \frac{\sum_{i=1}^{n_k} X_{i}}{n_k}\equiv \bar X_{k}.\]</span> While <span class="citation">Proschan, Lan, and Wittes (2006)</span> have used <span class="math inline">\(\delta\)</span> instead of <span class="math inline">\(\theta\)</span> in our notation, we stick more closely to the notation of <span class="citation">Jennison and Turnbull (2000)</span> where <span class="math inline">\(\theta\)</span> is used. For our example, we see <span class="math inline">\(\hat{\theta}_k\equiv\bar X_k\)</span> represents the sample average at analysis <span class="math inline">\(k\)</span>, <span class="math inline">\(1\le k\le K\)</span>. With a survival endpoint, <span class="math inline">\(\hat\theta_k\)</span> would typically represent a Cox model coefficient representing the logarithm of the hazard ratio for experimental vs control treatment and <span class="math inline">\(n_k\)</span> would represent the planned number of events at analysis <span class="math inline">\(k\)</span>, <span class="math inline">\(1\le k\le K.\)</span> Denoting <span class="math inline">\(t_k=n_k/N\)</span>, we assume that for some real-valued function <span class="math inline">\(\theta(t)\)</span> for <span class="math inline">\(t\ge 0\)</span> we have for <span class="math inline">\(1\le k\le K\)</span></p>
<p><span class="math display">\[E(\hat{\theta}_k) =\theta(t_k) =E(\bar X_k).\]</span> In the models of <span class="citation">Proschan, Lan, and Wittes (2006)</span> and <span class="citation">Jennison and Turnbull (2000)</span> we would have <span class="math inline">\(\theta(t)\)</span> equal to some constant <span class="math inline">\(\theta\)</span>. We assume further that for <span class="math inline">\(i=1,2,\ldots\)</span> <span class="math display">\[\hbox{Var}(X_{i})=1.\]</span> The sample average variance under this assumption is for <span class="math inline">\(1\le k\le K\)</span></p>
<p><span class="math display">\[\hbox{Var}(\hat\theta(t_k))=\hbox{Var}(\bar X_k) =  1/ n_k.\]</span> The statistical information for the estimate <span class="math inline">\(\hat\theta(t_k)\)</span> for <span class="math inline">\(1\le k\le K\)</span> for this case is <span class="math display">\[ \mathcal{I}_k \equiv \frac{1}{\hbox{Var}(\hat\theta(t_k))} = n_k.\]</span> We now see that <span class="math inline">\(t_k\)</span>, <span class="math inline">\(1\le k\le K\)</span> is the so-called information fraction at analysis <span class="math inline">\(k\)</span> in that <span class="math inline">\(t_k=\mathcal{I}_k/\mathcal{I}_K.\)</span></p>
</div>
<div id="z-process" class="section level2">
<h2 class="hasAnchor">
<a href="#z-process" class="anchor"></a>Z-process</h2>
<p>The Z-process is commonly used (e.g., <span class="citation">Jennison and Turnbull (2000)</span>) and will be used below to extend the computational algorithm in Chapter 19 of <span class="citation">Jennison and Turnbull (2000)</span> by defining equivalently in the first and second lines below for <span class="math inline">\(k=1,\ldots,K\)</span></p>
<p><span class="math display">\[Z_{k} = \frac{\hat\theta_k}{\sqrt{\hbox{Var}(\hat\theta_k)}}= \sqrt{\mathcal{I}_k}\hat\theta_k= \sqrt{n_k}\bar X_k.\]</span></p>
<p>The variance for <span class="math inline">\(1\le k\le K\)</span> is <span class="math display">\[\hbox{Var}(Z_k) = 1\]</span> and the expected value is</p>
<p><span class="math display">\[E(Z_{k})= \sqrt{\mathcal{I}_k}\theta(t_{k})= \sqrt{n_k}E(\bar X_k) .\]</span></p>
</div>
<div id="b-process" class="section level2">
<h2 class="hasAnchor">
<a href="#b-process" class="anchor"></a>B-process</h2>
<p>B-values are mnemonic for Brownian motion. For <span class="math inline">\(1\le k\le K\)</span> we define <span class="math display">\[B_{k}=\sqrt{t_k}Z_k\]</span> which implies <span class="math display">\[ E(B_{k}) = \sqrt{t_{k}\mathcal{I}_k}\theta(t_k) = t_k \sqrt{\mathcal{I}_K} \theta(t_k) = \mathcal{I}_k\theta(t_k)/\sqrt{\mathcal{I}_K}\]</span> and <span class="math display">\[\hbox{Var}(B_k) = t_k.\]</span></p>
<p>For our example, we have</p>
<p><span class="math display">\[B_k=\frac{1}{\sqrt N}\sum_{i=1}^{n_k}X_i.\]</span> It can be useful to think of <span class="math inline">\(B_k\)</span> as a sum of independent random variables.</p>
</div>
<div id="summary-of-e--z--and-b-processes" class="section level2">
<h2 class="hasAnchor">
<a href="#summary-of-e--z--and-b-processes" class="anchor"></a>Summary of E-, Z- and B-processes</h2>
<table class="table">
<colgroup>
<col width="22%">
<col width="17%">
<col width="47%">
<col width="12%">
</colgroup>
<thead><tr class="header">
<th align="left">Statistic</th>
<th align="left">Example</th>
<th align="left">Expected value</th>
<th align="left">Variance</th>
</tr></thead>
<tbody>
<tr class="odd">
<td align="left"><span class="math inline">\(\hat\theta_k\)</span></td>
<td align="left"><span class="math inline">\(\bar X_k\)</span></td>
<td align="left"><span class="math inline">\(\theta(t_k)\)</span></td>
<td align="left"><span class="math inline">\(\mathcal{I}_k^{-1}\)</span></td>
</tr>
<tr class="even">
<td align="left"><span class="math inline">\(Z_k=\sqrt{\mathcal{I}_k}\hat\theta_k\)</span></td>
<td align="left"><span class="math inline">\(\sqrt{n_k}\bar X_k\)</span></td>
<td align="left"><span class="math inline">\(\sqrt{\mathcal{I}_k}\theta(t_k)\)</span></td>
<td align="left"><span class="math inline">\(1\)</span></td>
</tr>
<tr class="odd">
<td align="left"><span class="math inline">\(B_k=\sqrt{t_k}Z_k\)</span></td>
<td align="left"><span class="math inline">\(\sum_{i=1}^{n_k}X_i/\sqrt N\)</span></td>
<td align="left"><span class="math inline">\(t_k\sqrt{\mathcal{I}_K}\theta(t_k)=\mathcal{I}_k\theta(t_k)/\sqrt{\mathcal{I}_K}\)</span></td>
<td align="left"><span class="math inline">\(t_k\)</span></td>
</tr>
</tbody>
</table>
</div>
<div id="conditional-independence-covariance-and-canonical-form" class="section level2">
<h2 class="hasAnchor">
<a href="#conditional-independence-covariance-and-canonical-form" class="anchor"></a>Conditional independence, covariance and canonical form</h2>
<p>We assume independent increments in the B-process. That is, for <span class="math inline">\(1\le j &lt; k\le K\)</span> <span class="math display">\[\tag{1} B_k - B_j \sim \hbox{Normal} (\sqrt{\mathcal{I}_K}(t_k\theta(t_k)- t_j\theta(t_j)), t_k-t_j)\]</span> independent of <span class="math inline">\(B_1,\ldots,B_j\)</span>. As noted above, for a given <span class="math inline">\(1\le k\le K\)</span> we have for our example <span class="math display">\[B_j=\sum_{i=1}^{n_j}X_i / \sqrt N.\]</span> Because of independence of the sequence <span class="math inline">\(X_i\)</span>, <span class="math inline">\(i=1,2,\ldots\)</span>, we immediately have for <span class="math inline">\(1\le j\le k\le K\)</span> <span class="math display">\[\hbox{Cov}(B_j,B_k) = \hbox{Var}(B_j) = t_j.\]</span> This leads further to <span class="math display">\[\hbox{Corr}(B_j,B_k)=\frac{t_j}{\sqrt{t_jt_k}}=\sqrt{t_j/t_k}=\hbox{Corr}(Z_j,Z_k)=\hbox{Cov}(Z_j,Z_k)\]</span> which is the covariance structure in the so-called <em>canonical form</em> of <span class="citation">Jennison and Turnbull (2000)</span>. For our example, we have <span class="math display">\[B_k=\frac{1}{\sqrt N}\sum_{i=1}^{n_k}X_i\]</span> and <span class="math display">\[B_k-B_j=\frac{1}{\sqrt N}\sum_{i=n_j + 1}^{n_k}X_i\]</span> and the covariance is obvious. We assume independent increments in the B-process that will be demonstrated for the simple example above. That is, for <span class="math inline">\(1\le j &lt; k\le K\)</span> <span class="math display">\[\tag{1} B_k - B_j \sim \hbox{Normal} (\mathcal{I}_k\theta(t_k)- \mathcal{I}_j\theta(t_j), t_k-t_j)\]</span> independent of <span class="math inline">\(B_1,\ldots,B_j\)</span>. For a given <span class="math inline">\(1\le j\le k\le K\)</span> we have for our example <span class="math display">\[B_j=\sum_{i=1}^{n_j}X_i / (\sqrt N\sigma).\]</span> Because of independence of the sequence <span class="math inline">\(X_i\)</span>, <span class="math inline">\(i=1,2,\ldots\)</span>, we immediately have for <span class="math inline">\(1\le j\le k\le K\)</span> <span class="math display">\[\hbox{Cov}(B_j,B_k) = \hbox{Var}(B_j) = t_j/t_k =\mathcal{I}_j/\mathcal{I}_k.\]</span> This leads to <span class="math display">\[\mathcal{I}_j/\mathcal{I}_k=\sqrt{t_j/t_k}=\hbox{Corr}(B_j,B_k)=\hbox{Corr}(Z_j,Z_k)=\hbox{Cov}(Z_j,Z_k)\]</span> which is the covariance structure in the so-called <em>canonical form</em> of <span class="citation">Jennison and Turnbull (2000)</span>. The independence of <span class="math inline">\(B_j\)</span> and <span class="math display">\[B_k-B_j=\sum_{i=n_j + 1}^{n_k}X_i/(\sqrt N\sigma)\]</span> is obvious for this example.</p>
</div>
</div>
<div id="test-bounds-and-crossing-probabilities" class="section level1">
<h1 class="hasAnchor">
<a href="#test-bounds-and-crossing-probabilities" class="anchor"></a>Test bounds and crossing probabilities</h1>
<p>In this section we define notation for bounds and boundary crossing probabilities for a group sequential design. We also define an algorithm for computing bounds based on a targeted boundary crossing probability at each analysis. The notation will be used elsewhere for defining one- and two-sided group sequential hypothesis testing. A value of <span class="math inline">\(\theta(t)&gt;0\)</span> will reflect a positive benefit.</p>
<p>For <span class="math inline">\(k=1,2,\ldots,K-1\)</span>, interim cutoffs <span class="math inline">\(-\infty \le a_k&lt; b_k\le \infty\)</span> are set; final cutoffs <span class="math inline">\(-\infty \le a_K\leq b_K &lt;\infty\)</span> are also set. An infinite efficacy bound at an analysis means that bound cannot be crossed at that analysis. Thus, <span class="math inline">\(3K\)</span> parameters define a group sequential design: <span class="math inline">\(a_k\)</span>, <span class="math inline">\(b_k\)</span>, and <span class="math inline">\(\mathcal{I}_k\)</span>, <span class="math inline">\(k=1,2,\ldots,K\)</span>.</p>
<div id="notation-for-boundary-crossing-probabilities" class="section level2">
<h2 class="hasAnchor">
<a href="#notation-for-boundary-crossing-probabilities" class="anchor"></a>Notation for boundary crossing probabilities</h2>
<p>We now apply the above distributional assumptions to compute boundary crossing probabilities. We use a shorthand notation in this section to have <span class="math inline">\(\theta\)</span> represent <span class="math inline">\(\theta()\)</span> and <span class="math inline">\(\theta=0\)</span> to represent <span class="math inline">\(\theta(t)\equiv 0\)</span> for all <span class="math inline">\(t\)</span>. We denote the probability of crossing the upper boundary at analysis <span class="math inline">\(k\)</span> without previously crossing a bound by</p>
<p><span class="math display">\[\alpha_{k}(\theta)=P_{\theta}(\{Z_{k}\geq b_{k}\}\cap_{j=1}^{i-1}\{a_{j}\le Z_{j}&lt; b_{j}\}),\]</span> <span class="math inline">\(k=1,2,\ldots,K.\)</span></p>
<p>Next, we consider analogous notation for the lower bound. For <span class="math inline">\(k=1,2,\ldots,K\)</span> denote the probability of crossing a lower bound at analysis <span class="math inline">\(k\)</span> without previously crossing any bound by</p>
<p><span class="math display">\[\beta_{k}(\theta)=P_{\theta}((Z_{k}&lt; a_{k}\}\cap_{j=1}^{k-1}\{ a_{j}\le Z_{j}&lt; b_{j}\}).\]</span> For symmetric testing for analysis <span class="math inline">\(k\)</span> we would have <span class="math inline">\(a_k= - b_k\)</span>, <span class="math inline">\(\beta_k(0)=\alpha_k(0),\)</span> <span class="math inline">\(k=1,2,\ldots,K\)</span>. The total lower boundary crossing probability for a trial is denoted by <span class="math display">\[\beta(\theta)\equiv\sum_{k=1}^{K}\beta_{k}(\theta).\]</span> Note that we can also set <span class="math inline">\(a_k= -\infty\)</span> for any or all analyses if a lower bound is not desired, <span class="math inline">\(k=1,2,\ldots,K\)</span>. For <span class="math inline">\(k&lt;K\)</span>, we can set <span class="math inline">\(b_k=\infty\)</span> where an upper bound is not desired. Obviously, for each <span class="math inline">\(k\)</span>, we want either <span class="math inline">\(a_k&gt;-\infty\)</span> or <span class="math inline">\(b_k&lt;\infty\)</span>.</p>
</div>
<div id="recursive-algorithms" class="section level2">
<h2 class="hasAnchor">
<a href="#recursive-algorithms" class="anchor"></a>Recursive algorithms</h2>
<p>We now provide a small update to the algorithm of Chapter 19 of <span class="citation">Jennison and Turnbull (2000)</span> to do the numerical integration required to compute the boundary crossing probabilites of the previous section and also identifying group sequential boundaries satisfying desired characteristics. The key to these calculations is the conditional power identitity in equation (1) above which allows building recursive numerical integration identities to enable simple, efficient numerical integration.</p>
<p>We define</p>
<p><span class="math display">\[g_1(z;\theta) = \frac{d}{dz}P(Z_1\le z) = \phi\left(z - \sqrt{\mathcal{I}_1}\theta(t_1)\right)\tag{2}\]</span></p>
<p>and for <span class="math inline">\(k=2,3,\ldots K\)</span> we recursively define the subdensity function</p>
<p><span class="math display">\[\begin{align}
g_k(z; \theta) &amp;= \frac{d}{dz}P_\theta(\{Z_k\le z\}\cap_{j=1}^{k-1}\{a_j\le Z_j&lt;b_j\}) \\
 &amp;=\int_{a_{k-1}}^{b_{k-1}}\frac{d}{dz}P_\theta(\{Z_k\le z |Z_{k-1}=z_{k-1}\})g_{k-1}(z_{k-1}; \theta)dz_{k-1}\\
 &amp;=\int_{a_{k-1}}^{b_{k-1}}f_k(z_{k-1},z;\theta)g_{k-1}(z_{k-1}; \theta)dz_{k-1}.\tag{3}
 \end{align}
\]</span> The bottom line notation here is the same as on p. 347 in <span class="citation">Jennison and Turnbull (2000)</span>. However, <span class="math inline">\(f_k()\)</span> here takes a slightly different form.</p>
<p><span class="math display">\[\begin{align}
f_k(z_{k-1},z;\theta) &amp;=\frac{d}{dz}P_\theta(\{Z_k\le z |Z_{k-1}=z_{k-1}\})\\
 &amp;=\frac{d}{dz}P_\theta(B_k - B_{k-1} \le z\sqrt{t_k}-z_{k-1}\sqrt{t_{k-1}})\\
 &amp;=\frac{d}{dz}\Phi\left(\frac{z\sqrt{t_k}-z_{k-1}\sqrt{t_{k-1}}-\sqrt{\mathcal{I}_K}(t_k\theta(t_k)- t_{k-1}\theta(t_{k-1}))}{\sqrt{t_k-t_{k-1}}}\right)\\
 &amp;=\frac{\sqrt{t_k}}{\sqrt{t_k-t_{k-1}}}\phi\left(\frac{z\sqrt{t_k}-z_{k-1}\sqrt{t_{k-1}}-\sqrt{\mathcal{I}_K}(t_k\theta(t_k)- t_{k-1}\theta(t_{k-1}))}{\sqrt{t_k-t_{k-1}}}\right)\\
 &amp;=\frac{\sqrt{\mathcal{I}_k}}{\sqrt{\mathcal{I}_k-\mathcal{I}_{k-1}}}\phi\left(\frac{z\sqrt{\mathcal{I}_k}-z_{k-1}\sqrt{\mathcal{I}_{k-1}}-(\mathcal{I}_k\theta(t_k)- \mathcal{I}_{k-1}\theta(t_{k-1}))}{\sqrt{\mathcal{I}_k-\mathcal{I}_{k-1}}}\right).\tag{3}
\end{align}\]</span></p>
<p>We have worked towards this last line due to its comparability to equation (19.4) on p. 347 of <span class="citation">Jennison and Turnbull (2000)</span> which assumes <span class="math inline">\(\theta(t_k)=\theta\)</span> for some constant <span class="math inline">\(\theta\)</span>; we re-write that equation slightly here as:</p>
<p><span class="math display">\[f_k(z_{k-1},z;\theta) = \frac{\sqrt{\mathcal{I}_k}}{\sqrt{\mathcal{I}_k-\mathcal{I}_{k-1}}}\phi\left(\frac{z\sqrt{\mathcal{I}_k}-z_{k-1}\sqrt{\mathcal{I}_{k-1}}-\theta(\mathcal{I}_k- \mathcal{I}_{k-1})}{\sqrt{\mathcal{I}_k-\mathcal{I}_{k-1}}}\right).\tag{4}\]</span> This is really the only difference in the computational algorithm for boundary crossing probabilities from the <span class="citation">Jennison and Turnbull (2000)</span> algorithm. Using the above recursive approach we can compute for <span class="math inline">\(k=1,2,\ldots,K\)</span></p>
<p><span class="math display">\[\alpha_{k}(\theta)=\int_{b_k}^\infty g_k(z;\theta)dz\tag{5}\]</span> and <span class="math display">\[\beta_{k}(\theta)=\int_{-\infty}^{a_k} g_k(z;\theta)dz.\tag{6}\]</span></p>
</div>
<div id="deriving-spending-boundaries" class="section level2">
<h2 class="hasAnchor">
<a href="#deriving-spending-boundaries" class="anchor"></a>Deriving spending boundaries</h2>
<p>We can now derive boundaries satisfying given boundary crossing probabilities using equations (2-6) above. Suppose for we have specified <span class="math inline">\(b_1,\ldots,b_{k-1}\)</span> and <span class="math inline">\(a_1,\ldots,a_{k-1}\)</span> and now wish to derive <span class="math inline">\(a_k\)</span> and <span class="math inline">\(b_k\)</span> such that equations (5) and (6) hold. We write the upper bound as a function of the probability of crossing we wish to derive.</p>
<p><span class="math display">\[\pi_k(b;\theta) = \int_b^\infty g_k(z;\theta)dz\]</span> <span class="math display">\[\pi_k^\prime(b;\theta) =\frac{d}{db}\pi_k(b;\theta)= -g_k(b; \theta).\tag{7}\]</span> If we have a value <span class="math inline">\(\pi_k(b^{(i)};\theta)\)</span> we can use a first order Taylor’s series expansion to approximate</p>
<p><span class="math display">\[\pi_k(b;\theta)\approx \pi_k(b^{(i)};\theta)+(b-b^{(i)})\pi_k^\prime(b^{(i)};\theta)\]</span> We set <span class="math inline">\(b^{(i+1)}\)</span> such that</p>
<p><span class="math display">\[\alpha_k(\theta)=\pi_k(b^{(i)}; \theta) + (b^{(i+1)}-b^{(i)})\pi^\prime(b^{(i)};\theta).\]</span></p>
<p>Solving for <span class="math inline">\(b^{(i+1)}\)</span> we have</p>
<p><span class="math display">\[b^{(i+i)} = b^{(i)} + \frac{\alpha_k(\theta) - \pi_k(b^{(i)};\theta)}{\pi_k^\prime(b^{(i)}; \theta)}= b^{(i)} - \frac{\alpha_k(\theta) - \pi_k(b^{(i)};\theta)}{g_k(b^{(i)}; \theta)}\tag{8}\]</span> and iterate until <span class="math inline">\(|b^{(i+1)}-b^{(i)}|&lt;\epsilon\)</span> for some tolerance level <span class="math inline">\(\epsilon&gt;0\)</span> and <span class="math inline">\(\pi_k(b^{(i+1)};\theta)-\alpha_k(\theta)\)</span> is suitably small. A simple starting value for any <span class="math inline">\(k\)</span> is</p>
<p><span class="math display">\[b^{(0)} = \Phi^{-1}(1- \alpha_k(\theta)) + \sqrt{\mathcal{I}_k}\theta(t_k).\tag{9}\]</span> Normally, <span class="math inline">\(b_k\)</span> will be calculated with <span class="math inline">\(\theta(t_k)=0\)</span> for <span class="math inline">\(k=1,2,\ldots,K\)</span> which simplifies the above. However, <span class="math inline">\(a_k\)</span> computed analogously will often use a non-zero <span class="math inline">\(\theta\)</span> to enable so-called <span class="math inline">\(\beta\)</span>-spending.</p>
</div>
</div>
<div id="numerical-integration" class="section level1">
<h1 class="hasAnchor">
<a href="#numerical-integration" class="anchor"></a>Numerical integration</h1>
<p>The numerical integration required to compute boundary probabilities and derive boundaries is the same as that defined in section 19.3 of <span class="citation">Jennison and Turnbull (2000)</span>. The single change is the replacement of the non-proportional effect size assumption of equation (3) above replacing the equivalent of equation (4) used for a constant effect size as in <span class="citation">Jennison and Turnbull (2000)</span>.</p>
</div>
<div id="references" class="section level1 unnumbered">
<h1 class="hasAnchor">
<a href="#references" class="anchor"></a>References</h1>
<div id="refs" class="references">
<div id="ref-JTBook">
<p>Jennison, Christopher, and Bruce W. Turnbull. 2000. <em>Group Sequential Methods with Applications to Clinical Trials</em>. Boca Raton, FL: Chapman; Hall/CRC.</p>
</div>
<div id="ref-PLWBook">
<p>Proschan, Michael A., K. K. Gordon Lan, and Janet Turk Wittes. 2006. <em>Statistical Monitoring of Clinical Trials. A Unified Approach.</em> New York, NY: Springer.</p>
</div>
<div id="ref-Tsiatis">
<p>Tsiatis, Anastasios A. 1982. “Repeated Significance Testing for a General Class of Statistics Use in Censored Survival Analysis.” <em>Journal of the American Statistical Association</em> 77: 855–61.</p>
</div>
</div>
</div>
  </div>

  <div class="col-md-3 hidden-xs hidden-sm" id="pkgdown-sidebar">

        <nav id="toc" data-toggle="toc"><h2 data-toc-skip>Contents</h2>
    </nav>
</div>

</div>



      <footer><div class="copyright">
  <p>Developed by Anderson Keaven, Yilong Zhang, Shirazi Amin.</p>
</div>

<div class="pkgdown">
  <p>Site built with <a href="https://pkgdown.r-lib.org/">pkgdown</a> 1.6.1.</p>
</div>

      </footer>
</div>

  


  </body>
</html>
